{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning (Decision Tree, and gradient boosting CatBoost, LightGBM)\n",
    "\n",
    "Create machine learning object, train the model, and predict output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load cleaned datasets\n",
    "train = pd.read_csv(\"train4.csv\", low_memory=False)\n",
    "pred = pd.read_csv(\"test4.csv\", low_memory=False)\n",
    "\n",
    "# Make sure that all varibles have float values.\n",
    "train = train.astype(dtype=float, inplace=True)\n",
    "pred = pred.astype(dtype=float, inplace=True)\n",
    "\n",
    "# Fill missing values with -999.0.\n",
    "train.fillna(value=-999.0, inplace=True)\n",
    "pred.fillna(value=-999.0, inplace=True)\n",
    "\n",
    "# Generate X, y, and X_test datasets.\n",
    "train_array = train.values\n",
    "X = train_array[:, 0:train.shape[1]-1]\n",
    "y = train_array[:, train.shape[1]-1]\n",
    "\n",
    "X_pred = pred.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Split X into training and validation datasets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training data): 0.985\n",
      "Accuracy score (test data): 0.984\n",
      "\n",
      "Cross validation - Accuracy score: 0.984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create decision tree classification object\n",
    "tree = DecisionTreeClassifier(max_depth=5, random_state=88)\n",
    "\n",
    "# Train the model on training sets\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Compare the accuracy scores of training and testing sets\n",
    "print(\"Accuracy score (training data): {0:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Accuracy score (test data): {0:.3f}\".format(tree.score(X_test, y_test)))\n",
    "print()\n",
    "# Check cross validation score\n",
    "print(\"Cross validation - Accuracy score: {0:.3f}\".format(np.mean(cross_val_score(tree, X_test, y_test, scoring=\"accuracy\", cv=10))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction result\n",
      "Counts of N: 199989\n",
      "Counts of Y: 11\n"
     ]
    }
   ],
   "source": [
    "# Predict output\n",
    "y_predicted = tree.predict(X_pred)\n",
    "\n",
    "# Count the values of response variable in prediction result\n",
    "count_0 = 0\n",
    "count_1 = 0\n",
    "for item in y_predicted:\n",
    "    if item == 0.0:\n",
    "        count_0 += 1\n",
    "    else:\n",
    "        count_1 += 1\n",
    "print(\"Prediction result\")\n",
    "print(\"Counts of N:\", count_0)\n",
    "print(\"Counts of Y:\", count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output prediction as submission.csv file\n",
    "# Submission should contain only two columns: CUSTOMER_ID and RESPONDERS\n",
    "customer_id_df = pd.read_csv(\"pred_customer_id.csv\", low_memory=False, header=None)\n",
    "customer_id = customer_id_df.values\n",
    "submission = pd.DataFrame({\"CUSTOMER_ID\": customer_id[:, 0], \"RESPONDERS\": y_predicted}, columns=[\"CUSTOMER_ID\", \"RESPONDERS\"])\n",
    "submission.loc[:, \"RESPONDERS\"].replace(to_replace=[0.0, 1.0], value=[\"N\", \"Y\"], inplace=True)\n",
    "submission.to_csv(\"submisson.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip file for submission.csv\n",
    "from zipfile import ZipFile\n",
    "with ZipFile(\"submission.zip\", \"w\") as myzip:\n",
    "    myzip.write(\"submisson.csv\")\n",
    "myzip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training data): 0.985\n",
      "Accuracy score (testing data): 0.984\n",
      "\n",
      "Cross validation score: 0.985\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Create CatBoost classification object\n",
    "parameters = {\"iterations\":200, \n",
    "              \"learning_rate\": 0.02, \n",
    "              \"depth\": 6, \n",
    "              \"l2_leaf_reg\":3}\n",
    "\n",
    "cb = CatBoostClassifier(**parameters)\n",
    "\n",
    "# Train the model on training sets\n",
    "cb.fit(X_train, y_train)\n",
    "\n",
    "# Compare the accuracy scores of training and testing sets.\n",
    "print(\"Accuracy score (training data): {0:.3f}\".format(cb.score(X_train, y_train)))\n",
    "print(\"Accuracy score (testing data): {0:.3f}\".format(cb.score(X_test, y_test)))\n",
    "print()\n",
    "# Check cross validation score\n",
    "print(\"Cross validation score: {0:.3f}\".format(round(np.mean(cross_val_score(cb, X_test, y_test, scoring=\"accuracy\", cv=10)), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoostClassifier is the slowest among the three classifier used here on large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction result\n",
      "Counts of N: 200000\n",
      "Counts of Y: 0\n"
     ]
    }
   ],
   "source": [
    "# Predict output\n",
    "y_predicted = cb.predict(X_pred)\n",
    "\n",
    "# Count the values of response variable in prediction result\n",
    "count_0 = 0\n",
    "count_1 = 0\n",
    "for item in y_predicted:\n",
    "    if item == 0.0:\n",
    "        count_0 += 1\n",
    "    else:\n",
    "        count_1 += 1\n",
    "print(\"Prediction result\")\n",
    "print(\"Counts of N:\", count_0)\n",
    "print(\"Counts of Y:\", count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training data): 0.985\n",
      "Accuracy score (testing data): 0.984\n",
      "\n",
      "Cross validation score: 0.985\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Train with gradient boosting LightGBM algorithm and calculate scores\n",
    "param = {\"num_leaves\":255, \"max_depth\":8, \"learning_rate\":0.05, \"max_bin\":255}\n",
    "lgbm = LGBMClassifier(**param)\n",
    "\n",
    "# Train the model on training sets\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "# Compare the accuracy scores of training and testing sets.\n",
    "print(\"Accuracy score (training data): {0:.3f}\".format(lgbm.score(X_train, y_train)))\n",
    "print(\"Accuracy score (testing data): {0:.3f}\".format(lgbm.score(X_test, y_test)))\n",
    "print()\n",
    "# Check cross validation score\n",
    "print(\"Cross validation score: {0:.3f}\".format(round(np.mean(cross_val_score(lgbm, X_test, y_test, scoring=\"accuracy\", cv=10)), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM is the most fast among the three on large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction result\n",
      "Counts of N: 199993\n",
      "Counts of Y: 7\n"
     ]
    }
   ],
   "source": [
    "# Predict output\n",
    "y_predicted = lgb.predict(X_pred)\n",
    "\n",
    "# Count the values of response variable in prediction result\n",
    "count_0 = 0\n",
    "count_1 = 0\n",
    "for item in y_predicted:\n",
    "    if item == 0.0:\n",
    "        count_0 += 1\n",
    "    else:\n",
    "        count_1 += 1\n",
    "print(\"Prediction result\")\n",
    "print(\"Counts of N:\", count_0)\n",
    "print(\"Counts of Y:\", count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
