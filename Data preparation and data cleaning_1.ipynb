{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation and data cleaning (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw train and test datasets.\n",
    "train_raw = pd.read_csv(\"train_raw.csv\", low_memory=False)\n",
    "test_raw = pd.read_csv(\"test_raw.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300000 entries, 0 to 299999\n",
      "Columns: 333 entries, CUSTOMER_ID to RESPONDERS\n",
      "dtypes: float64(236), int64(4), object(93)\n",
      "memory usage: 762.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the train_raw.info(), we can know:\n",
    "1) The train dataset has 300,000 rows.\n",
    "2) The train dataset has 333 columns. The 1st column is CUSTOMER_ID, and the last column is RESPONDERS, the target variable. The left 331 columns are variables.\n",
    "3) The dtype of 236 columns is float64, the dtype of 4 columns is int64, and the dtype of 93 columns is object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 332 entries, CUSTOMER_ID to SCRUB_EMI\n",
      "dtypes: float64(238), int64(4), object(90)\n",
      "memory usage: 506.6+ MB\n"
     ]
    }
   ],
   "source": [
    "test_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the test_raw.info(), we can know:\n",
    "1) The test dataset has 200,000 rows.\n",
    "2) The test dataset has 332 columns. The 1st column is CUSTOMER_ID. The left 331 columns are variables.\n",
    "3) The dtype of 238 columns is float64, the dtype of 4 columns is int64, and the dtype of 90 columns is object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 3, 6, 12, 14, 15, 16, 18, 18, 18]\n",
      "\n",
      "[300000, 300000, 300000, 300000, 300000, 300000, 300000, 300000, 300000, 300000, 300000, 300000, 300000, 300000, 300000, 300000, 300000, 300000, 300000, 300000]\n"
     ]
    }
   ],
   "source": [
    "# Examine the number of values in every column of the train dataset.\n",
    "\n",
    "val_counts = []\n",
    "for i in range(0, train_raw.shape[1]):\n",
    "    val_counts.append(train_raw.iloc[:, i].count())\n",
    "val_counts_sorted = sorted(val_counts)\n",
    "print(val_counts_sorted[:20])\n",
    "print()\n",
    "print(val_counts_sorted[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many columns of the train dataset have a very small amount of values. The test set has the same problem.\n",
    "Next, I'm going to remove those columns that have a small amount of values from both train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To generate lists of selected columns containing a large number of values in the train set.\n",
    "# Here, columns containing >= (len(train.shape[0]))/3, that is 300,000/3=100,000, values are chosen.\n",
    "# This list will be used when generating new datasets.\n",
    "# A sub list of columns with object dtype is also generated.\n",
    "\n",
    "all_train_cols = list(train_raw)\n",
    "train_cols = []    # List of columns in train set to be chosen.\n",
    "train_cols_obj = []    # A sub list of columns with object dtype.\n",
    "for col in all_train_cols:\n",
    "    if (train_raw[col].count()) >= ((train_raw.shape[0])/3):\n",
    "        train_cols.append(col)\n",
    "        if train_raw[col].dtype == \"object\":\n",
    "            train_cols_obj.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'OCCUP_ALL_NEW'), (2, 'ACT_TYPE'), (2, 'CARD_AUTOMOBILE_MON_01'), (2, 'CARD_ENTMNT_MON_01'), (2, 'CARD_HOBBY_MON_01'), (2, 'CARD_HOME_DECOR_MON_01'), (2, 'CARD_HOTEL_MON_01'), (2, 'CARD_JEWELLERY_MON_01'), (2, 'CARD_MEDICAL_MON_01'), (2, 'CARD_PRSNL_CARE_MON_01'), (2, 'CARD_RESTAURANT_MON_01'), (2, 'CARD_TRAVEL_MON_01'), (2, 'CC_ACTIVE'), (2, 'CC_HOLD'), (2, 'CREDIT_ACT'), (2, 'DC_ACTIVE'), (2, 'DC_HOLD'), (2, 'DEBIT_ACT'), (2, 'FINANCE_MON_01'), (2, 'INMON_01KET_MON_01'), (2, 'JOBS_MON_01'), (2, 'LIFESTYLE_MON_01'), (2, 'RESPONDERS'), (2, 'TOP14_CITY'), (2, 'TOP9_CITY'), (2, 'TRAVEL_MON_01'), (3, 'CHANNEL_CLICK_DISP'), (3, 'GENDER'), (3, 'TOP_CORP_TAG'), (5, 'LEGAL_ENTITY'), (11, 'DESIGNATION_FINAL'), (20, 'NEFT_CC_CATEGORY'), (20, 'NEFT_DC_CATEGORY'), (21, 'IMPS_CC_CATEGORY_MON_01'), (21, 'TPT_CC_CATEGORY_MON_01'), (21, 'TPT_DC_CATEGORY_MON_01'), (141, 'PA_PQ_TAG'), (27857, 'ZIP_CODE_FINAL')]\n"
     ]
    }
   ],
   "source": [
    "# To check the number of unique values of selected object columns\n",
    "\n",
    "num_obj_var = []\n",
    "for col in train_cols_obj:\n",
    "    df = train_raw.loc[:, [col]]\n",
    "    df_array = df.values\n",
    "    set_ = set(df_array[:,0])\n",
    "    num_obj_var.append((len(set_), col))\n",
    "print(sorted(num_obj_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable \"OCCUP_ALL_NEW\" only has one unique value in both train and test datasets. It can be removed. The variable \"ZIP_CODE_FINAL\" has the most unique values (27857) and the variable \"PA_PQ_TAG\" also has many unique values (141). I'll check the values in the two variables, find the pattern of the values, and transform the object values to numeral values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove OCCUP_ALL_NEW from the list of selected columns.\n",
    "train_cols.remove(\"OCCUP_ALL_NEW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new train and test sets according to the list of selected column.\n",
    "# Also generate a subset of Customer_ID for test\n",
    "\n",
    "# Generate new train set and output as csv file. The new train set has 86 features and the response variable\n",
    "train = train_raw[train_cols[1:]]\n",
    "train.to_csv(\"train1.csv\", index=None)\n",
    "\n",
    "# Generate a Customer_ID set for test and output as csv file. It will be used when reporting the prediction result.\n",
    "test_customer_id = test_raw[train_cols[0]]\n",
    "test_customer_id.to_csv(\"test_customer_id.csv\", index=None)\n",
    "\n",
    "# Generate new test set and output as csv file. The new test set has 86 features only.\n",
    "test = test_raw[train_cols[1:-1]]\n",
    "test.to_csv(\"test1.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can stop here and take a break."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
